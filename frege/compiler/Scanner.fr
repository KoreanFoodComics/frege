{- «•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»

    Copyright © 2011, Ingo Wechsung
    All rights reserved.

    Redistribution and use in source and binary forms, with or
    without modification, are permitted provided that the following
    conditions are met:

        Redistributions of source code must retain the above copyright
        notice, this list of conditions and the following disclaimer.

        Redistributions in binary form must reproduce the above
        copyright notice, this list of conditions and the following
        disclaimer in the documentation and/or other materials provided
        with the distribution. Neither the name of the copyright holder
        nor the names of its contributors may be used to endorse or
        promote products derived from this software without specific
        prior written permission.

    THIS SOFTWARE IS PROVIDED BY THE
    COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR
    IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
    PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER
    OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
    SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
    LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
    USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
    AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
    LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
    IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
    THE POSSIBILITY OF SUCH DAMAGE.

    «•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•»«•» -}
{--
 * This is the scanner for the frege compiler.
 *
 * Essentialy, there are the following important functions:
 * - the 'lex' function turns a list of strings into a list of 'Token's.
 * - the 'layout' function takes the output from 'scan' and inserts
 *   braces and semicolons according to layout rules.
 * - the 'substAllOp' functions scans the output of the scan function and
 *   replaces sequences of single characters with operator symbols according
 *   to a table.
 *
 * The 'lex' function has no way to know what operators are defined in the
 * current source file or in imported packages. In previous versions of the
 * compiler, this has been solved by calling import and updating the operator tree
 * via a reference as soon as the parser reduced an "import" or "infix" declaration.
 * Nowadays, we
 * 0. build an initial operator table from the Prelude
 * 1. scan without knowledge of the operators,
 * 2. do the layout,
 * 3. look for fixity definitions and imports
 * 4. complete the operator table
 *    (which causes 'IO' actions in case of imports)
 * 5. substitute characters with operators
 *
 * The resulting token list is ready to be passed to the parser.
 * This way, parser and scanner are decoupled and are pure functions,
 * with the exception of the part that builds the operator table.
 *
 -}


{-
 * $Author$
 * $Revision$
 * $Date$
 * $Id$
 -}
package frege.compiler.Scanner where

--- This is $Revision$
public version = v "$Revision$" where
    v (m ~ #(\d+)#) | Just g <- m.group 1 = g.atoi
    v _ = 0


-- import of library packages


import frege.List(Tree, keys, contains, fromKeys, each)
import Data.List as DL(partitioned, takeUntil)

-- import of compiler packages
import frege.compiler.Data       except (is)
import frege.compiler.Nice       except (group, layout, break)
import frege.compiler.Classtools (Operator, OpArr)
import frege.compiler.Utilities  as U(cval)

data CharSeq s = native java.lang.CharSequence where
    pure native charAt                                  :: CharSeq Immutable -> Int -> Char
    pure native length                                  :: CharSeq Immutable -> Int
    pure native subSeq  subSequence                     :: CharSeq Immutable -> Int -> Int -> CharSeq Immutable
    pure native toString                                :: CharSeq Immutable -> String
    pure native fromString "(java.lang.CharSequence)"   :: String -> CharSeq Immutable

{--
    [usage] @slurp filename encoding@
    [return] the content of text file @filename@ appropriatly decoded according to the files @encoding@
-}
native slurp frege.runtime.CompilerSupport.slurp :: String -> String -> IO (Exception String)

{--
 * A map of keywords to 'TokenID's
 -}
kwtree = Tree.insertlist Nil [
    ("package", PACKAGE),
    ("module", PACKAGE),
    ("import" ,  IMPORT),
    ("native" ,  NATIVE),
    ("if" ,  IF),
    ("then" ,  THEN),
    ("else" ,  ELSE),
    ("class" ,  CLASS),
    ("interface" ,  CLASS),
    ("where" ,  WHERE),
    ("instance" ,  INSTANCE),
    ("of" ,  OF),
    ("derive" ,  DERIVE),
    ("data" ,  DATA),
    -- ("extends" ,  EXTENDS),
    ("case" ,  CASE),
    ("let" ,  LET),
    ("in" ,  IN),
    ("type" ,  TYPE),
    ("true" ,  TRUE),
    ("false" ,  FALSE),
    ("protected" ,  PROTECTED),
    ("private" ,  PRIVATE),
    ("public" ,  PUBLIC),
    ("pure",     PURE),
    ("abstract", ABSTRACT),
    ("do" ,  DO),
    ("forall" ,  FORALL),
    -- ("continue" ,  CONTINUE),
    -- ("break" ,  BREAK),
    -- ("while" ,  WHILE),
    ("infix" ,  INFIX),
    ("infixl" ,  INFIXL),
    ("infixr" ,  INFIXR)];


{--
 * checks if a user defined operator obeys certain rules:
 * - it must not be one of "=" "|" "," ";" "." "\\" "_" "!" "?" "-"
 * - it must not be one of "::" "<-" "->" or "=>"
 * - it must not contain braces, square brackets or parentheses
 * - it must not conatin one of the quoting characters " \' ` or #
 * - it must not conatin digits
 * - it must consist of either all word characters or all non word characters
 -}
validop "=" = false;
validop "|" = false;
validop "?" = false;
validop "!" = false;
validop "-" = false;
validop "," = false;
validop ";" = false;
validop "." = false;
validop "\\" = false;
validop "_" = false;
validop "::" = false;
validop "<-" = false;
validop "->" = false;
validop "=>" = false;
validop #[\(\[\{\}\]\)]# = false;
validop #["`'\#]# = false;
validop #\d# = false;
validop #^\w+$# = true;
validop #^\W+$# = true;
validop _ = false;

{--
 * tells if character is forbidden in operator
 -}
-- forbidden ','  = true
-- forbidden '.'  = true
-- forbidden ';'  = true
forbidden '#'  = true   -- #
forbidden '´'  = true   -- ´
forbidden '"'  = true   -- "
forbidden '\'' = true
forbidden '`'  = true
forbidden '('  = true
forbidden ')'  = true
forbidden '['  = true
forbidden ']'  = true
forbidden '{'  = true
forbidden '}'  = true
forbidden _    = false


--- check whether 'Token' is a specific char
is :: Token -> Char -> Bool
is t c = t.tokid == CHAR && t.value.charAt 0 == c

--- check whether 'Token' is not a specific char
isNot :: Token -> Char -> Bool
isNot t c = t.tokid != CHAR || t.value.charAt 0 != c



{--
    This function does the layout on a list of
    'Token's. The result is another list
    of 'Token's with some extra semicolons
    and braces in the correct places.

    The first argument is the context represented by a list of integers,
    where each element is either:
    - Zero, indicating that the enclosing context is explicit
     (i.e. the programmer supplied the opening brace).
     If the innermost context is 0, then no layout tokens will be inserted until
     either the enclosing context ends or a new context is pushed.
    - A positive integer, which is the indentation column of the enclosing layout context.

    The /indentation/ of a token is the column number indicating the start of that token;
    the indentation of a line is the indentation of its leftmost lexeme.
    To determine the column number, assume a fixed-width font. For the purposes
    of the layout rule, Unicode characters in a source
    program are considered to be of the same, fixed, width as an ASCII character.
    The first column is designated column 1, not 0.

    The layout is done according to the following rules:

-}
layout :: [Int] -> [Token] -> [Token]

---  1) an explicit \'{\' starts a new explicit context
layout !ctx (t1:ts)
    | t1 `is` '{' = t1 : layout (0:ctx) ts

---  2) an explicit \'}\' can only occur in explicit context and closes this context
layout (0:ms) (t1:ts)
    | t1 `is` '}', t1.col > 0  = layout ms (Token CHAR "}" t1.line 0 t1.offset:ts)

{--
    3) if a *@let@*, *@do@*, *@where@* or *@of@* is not followed by \'{\'
       and the position of the next token is greater than the
       current context, insert \'{\' and push that position as new context.

    4) If the position of the first token on a line matches the context,
       a \';\' is inserted before that token, except when the last token
       on the last line was already a semicolon.

    5) If the position of the first token on a line is less than the context,
       the context is closed and a closing brace is inserted.

    6) If *@in@* is found in layout mode
       without preceding closing brace, the closing brace is inserted
       and the context is closed

    7) At the end of the program, if there are open layout contexts,
       a corresponding number of closing braces is inserted.
-}
layout (m:ms) (t1:t2:ts)
    | kw t1.tokid, t2 `isNot` '{', t2.col > m
    = t1 : Token CHAR "{" t1.line 0 (t1.offset+t1.value.length) : layout (t2.col:m:ms) (t2:ts)
    | t2.line > t1.line, t2.col == m, t1 `isNot` ';'
    = t1 : Token CHAR ";" t1.line 0 (t1.offset+t1.value.length) : layout (m:ms) (t2:ts)
    | t2.line > t1.line, t2.col < m
    = t1 : layout ms (Token CHAR "}" t1.line 0 (t1.offset+t1.value.length): t2 : ts)
    | m != 0, t2.tokid == IN, t1 `isNot` '}'
    = t1 : Token CHAR "}" t1.line 0 (t1.offset+t1.value.length) : layout ms (t2:ts)
    where
        kw LET = true; kw DO  = true; kw WHERE = true; kw OF = true; kw _ = false

layout ms (t1:ts) = t1:layout ms ts
layout [0] []     = []              -- proper end.
layout (m:ms) []
    | m > 0 = Token CHAR "}" Int.maxBound Int.maxBound Int.maxBound : layout ms []
    | otherwise = layout ms []    -- explicit brace missing

layout ms ts =
    traceLn ("layout " ++ show ms ++ "   " ++ show (take 3 ts)) `seq` []

infixr 13 `!:`
!a !: as = a : as

{--
    Scan a 'CharSeq' and take care of offsets
-}
lex :: CharSeq Immutable -> Int -> Int -> Int -> [Token]
lex !cs !line !col !start
    | endOfSeq        = []
    | ch == '\n'      = lex cs (line+1) 1   (start+1)
    | ch.isWhitespace = lex cs line (col+1) (start+1)
    | ch.isLowerCase  = case ident (start+1) of
                            !end -> case Token VARID (seq end) line col start of
                                tok -> case Tree.lookupS kwtree tok.value of
                                    Just f  -> tok.{tokid = f} !: lex cs line (col+end-start) end
                                    Nothing -> tok             !: lex cs line (col+end-start) end
    | ch.isUpperCase  = case ident (start+1) of
                            !end
                                | at end == '.' = Token QUALIFIER (seq end) line col start !: lex cs line (col+end-start+1) (end+1)
                                | otherwise     = Token CONID     (seq end) line col start !: lex cs line (col+end-start) end
                            {-
                                 | at end == '.',
                                   (at (end+1)).isUpperCase,
                                   end2 <- ident (end+1),
                                   at end2 == '.'
                                             = Token QUALIFIER (seq (end2+1)) line col start !: lex cs line (col+end2-start+1) (end2+1)
                                 | at end  == '.'
                                             = Token QUALIFIER (seq (end+1)) line col start  !: lex cs line (col+end-start+1) (end+1)
                                 | otherwise = Token CONID     (seq end)     line col start  !: lex cs line (col+end-start) end
                                 -}
    | ch == '0', at (start+1) == 'x' || at (start+1) == 'X', hexdigit (at (start+2))
                      = hexNumber    (start+2)
    | digit ch        = integer      (start+1)
    | ch == '{'       = commentStart (start+1)
    | ch == '-'       = commentStart (start+1)
    | ch == '\''      = lexQuoted    (start+1)
    | ch == '"'       = lexQuoted    (start+1) -- "
    | ch == '#'       = lexQuoted    (start+1) -- #
    | ch == '´'       = lexQuoted    (start+1)
    | ch == '`'       = lexQuoted    (start+1)
    | otherwise       = Token CHAR (ctos ch) line col start !: lex cs line (col+1) (start+1)
    where
        endOfSeq    = start >= cs.length      -- assume that length is a cheap operation on char sequences
        !ch         = if endOfSeq then '\0' else cs.charAt start
        seq end     = (cs.subSeq start end).toString
        digit ch    = ch >= '0' && ch <= '9'
        hexdigit ch = digit ch || ch >= 'a' && ch <= 'f' || ch >= 'A' && ch <= 'F'
        at i        = if i < cs.length then cs.charAt i else '\0'
        -- parse a quoted construct
        lexQuoted end
            | ch == '\\',
              end+1 < cs.length       = lexQuoted (end+2)
            | end >= cs.length        = [Token LEXERROR (seq end) line col start]
            | ch == '\n'              = Token LEXERROR (seq end) line col start !: lex cs line (col+end-start) end
            | ch != at start          = lexQuoted (end+1)
            | otherwise               = case at start of
                '"'  -> Token STRCONST (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1) -- "
                '\'' -> Token CHRCONST (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
                '#'  -> Token REGEXP   (cs.subSeq (start+1) end).toString line col start !: lex cs line (col+end-start+1) (end+1) -- #
                '´'  -> Token REGEXP   (cs.subSeq (start+1) end).toString line col start !: lex cs line (col+end-start+1) (end+1)
                _    -> Token SOMEOP   (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            where
                !ch = at end
        -- parse a hexadecimal number "
        hexNumber end
            | hexdigit ch             = hexNumber (end+1)
            | ch == 'l' || ch == 'L'  = Token LONGCONST (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            | otherwise               = Token INTCONST  (seq end)     line col start !: lex cs line (col+end-start)   end
            where
                !ch       = at end

        -- parse a number
        integer end
            -- end >= cs.length       = [num]
            | digit ch               = integer (end+1)
            | ch == '_',
              digit (at (end+1)) && digit (at (end+2)) && digit (at (end+3)) && not (digit (at (end+4)))
                                     = integer (end+4)
            | ch == 'l' || ch == 'L' = Token LONGCONST (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            | ch == 'n' || ch == 'N' = Token BIGCONST  (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            | ch == 'f' || ch == 'F' = Token FLTCONST  (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            | ch == 'd' || ch == 'D' = Token DBLCONST  (seq (end+1)) line col start !: lex cs line (col+end-start+1) (end+1)
            | ch == '.',
              digit (at (end+1))     = floatPart (end+1)
            | ch == 'e' || ch == 'E',
              digit (at (end+1))     = floatPart2 (end+1)
            | otherwise              = num !: lex cs line (col+end-start) end
            where
                num       = Token INTCONST (seq end) line col start
                !ch       = at end
                -- parse the first floating part, pointer is at first digit after .
                floatPart end
                    | digit ch                                  = floatPart (end+1)
                    | ch `elem` ['d', 'D', 'f', 'F']            = integer end
                    | ch == 'e' || ch == 'E',
                      at (end+1) == '+' || at (end+1) == '-',
                      digit (at (end+2))                        = floatPart2 (end+2)
                    | ch == 'e' || ch == 'E',
                      digit (at (end+1))                        = floatPart2 (end+1)
                    | otherwise                                 = Token DBLCONST  (seq end) line col start !: lex cs line (col+end-start) end
                    where
                        ch        = at end
                -- parse the second floating part, pointer is at first digit after "e+", "e-" or "e"
                -- see if we can get a documentation comment
                floatPart2 end
                    | digit ch                                  = floatPart2 (end+1)
                    | ch `elem` ['d', 'D', 'f', 'F']            = integer end
                    | otherwise                                 = Token DBLCONST  (seq end) line col start !: lex cs line (col+end-start) end
                    where
                        ch        = at end
        commentStart end
            | at end == '-' = lexComment 0 (at start == '{') proto cs line (col+2) (start+2)
            | otherwise     =  brace !: rest
            where
                brace = Token {tokid = CHAR, line, col, offset = start, value = ctos (at start)}
                rest  = lex cs line (col+1) end
                proto = Token DOCUMENTATION "" line col start
        ident end
            | (at end).isLetterOrDigit || at end == '_' = ident (end+1)
            | otherwise = skipApos end
        skipApos end
            | at end == '\''        = skipApos (end+1)
            | otherwise             = end



lexComment :: Int -> Bool -> Token -> CharSeq Immutable -> Int -> Int -> Int -> [Token]
lexComment !nest !block !proto !cs !line !col !i
    | i >= cs.length = if block
                        then [proto.{tokid=LEXERROR, value = (cs.subSeq proto.offset i).toString}]
                        else if at (proto.offset+2) == '-'
                            then [proto.{value = "   "}]
                            else [proto.{tokid = COMMENT, value = "  "}]
    | block,
      at i     == '-',
      at (i+1) == '}'
                     =  if nest == 0
                        then if at (proto.offset+2) == '-'
                            then proto.{value = subseq i ++ "     "}                  !: lex cs line (col+2) (i+2)
                            else proto.{tokid = COMMENT, value = subseq i ++ "     "} !: lex cs line (col+2) (i+2)
                        else lexComment (nest-1) block proto cs line (col+2) (i+2)
    | block,
      at i     == '{',
      at (i+1) == '-'
                     =  lexComment (nest+1) block proto cs line (col+2) (i+2)
    | block,
      at i == '\n'   =  lexComment nest block proto cs (line+1) 1        (i+1)
    | at i == '\n'   =  if at (proto.offset+2) == '-'
                            then proto.{value = subseq i ++ "   "}                  !: lex cs line col i
                            else if i == proto.offset+2         -- --\n do NOT look further
                            then proto.{tokid = COMMENT, value = "  "} !: lex cs line col i
                            else proto.{tokid = COMMENT, value = subseq i ++ "   "} !: lex cs line col i
    | otherwise      =  lexComment nest block proto cs line     (col+1)  (i+1)
    where
        at n = if n >= cs.length then '\0' else cs.charAt n
        subseq n = (cs.subSeq (proto.offset+3) n).toString


{--
 * Find @infix@ and @import@ declarations in token stream.
 -}
findInfixImports :: [Token] -> [[Token]]
findInfixImports ts = loop start ts where
    start = [[Token IMPORT "import" 0 0 0, Token VARID pPreludeBase.un 0 0 0]] -- import frege.Prelude
    loop acc [] = acc
    loop acc (t1:ts)
        | wanted (Token.tokid t1) = loop ((t1:this ts) : acc) (tail ts)
        | otherwise = loop acc ts
        where
            isImport = Token.tokid t1 == IMPORT
            wanted IMPORT = true
            wanted INFIXL = true
            wanted INFIXR = true
            wanted INFIX  = true
            wanted _      = false
            -- no separators
            consecutive :: [Token] -> [Token]
            consecutive (t1:(ts@t2:_))
                | t1.vor t2                          = t1:consecutive ts
                | otherwise                          = [t1]
            consecutive rest                         = rest
            separator t = t `is` '}' || t `is` ';'
            noComment t = Token.tokid t != COMMENT

            this ts = if isImport then consecutive (takeUntil separator tss) else takeUntil separator tss
                where tss = filter noComment ts

--- special symbols in tree
specialT = Tree.fromList [("::", DCOLON), 
                            ("=>", EARROW), ("⇒", EARROW), 
                            ("->", ARROW),  ("→", ARROW), 
                            ("<-", GETS),   ("←", GETS)]

--- find the package name of an import this one depends on
getPackage prefix [] = Nothing
getPackage prefix (t1:ts)
    | Token.tokid t1 == IMPORT, name != prefix = Just name
    | otherwise = Nothing
    where name = prefix ++ (magicPack • fold (++) "" • map vt • takeWhile packToken) ts
          vt t = case Token.tokid t of
            QUALIFIER -> t.value ++ "."
            _         -> t.value

getPackages prefix imps = [ s | Just s <- map (getPackage prefix) imps ]
{--
 * build a map from 'String's to 'TokenID's, which serves as dictionary of operators
 -}
-- processInfixImport :: [Token] ->(String ->  Either (Line, String) (Tree String TokenID)
processImports prefix getop (err@Left _) xs = StG.return err
processImports prefix getop (tree@Right _) [] = StG.return tree
processImports prefix getop (tree@Right _) (cmd:cmds)
        | (tss@t1:ts) <- cmd, Token.tokid t1 == IMPORT = do
            imp <- mkImport (Pos t1 t1) tss tree
            processImports prefix getop imp cmds
        | otherwise = processImports prefix getop tree cmds
        where
    mkImport _ _  (err@Left _)    = StG.return err
    mkImport n ts (tree@Right _)
        | null name = do
            U.error n (msgdoc "Package name missing after `import´")
            StG.return tree
        | otherwise = do
            (loaded::Exception (Maybe OpArr)) <- getop name
            g <- getST
            case loaded of
                -- we can ignore non existance of frege.Prelude for now,
                -- because either we are compiling frege.Prelude itself, when it can't be
                -- there already, or we are compiling something else and then we will
                -- see the error in the import pass, because every package except frege.Prelude
                -- will try to import frege.Prelude
                Left _ | name == pPreludeBase.unpack g -> StG.return tree
                Left jex           -> do
                    let err = (msgdoc ("Could not import package "
                                            ++ name
                                            ++ " (" ++ show jex ++ ")"))
                    return (Left (n, err))
                Right (Just oparr) -> StG.return $ fold ins tree [ oparr.[i] | i <- 0..oparr.length - 1]
                _                  -> StG.return $ tree      -- no operators
        where
            name = fromMaybe "" (getPackage prefix ts)
            -- loaded = getOperators loader name
            ins (err@Left _)   _        = err
            -- ins (tree@Right _) Nothing  = tree
            ins (Right tree)  op
                -- later imported ops replace earlier ones
              {- | Just _ <- Tree.lookup tree key = Right tree
              | otherwise -} = Right result where
                result = Tree.insert tree key val
                !key = Operator.name op
                !xop | Operator.kind op == 0  = LOP0
                     | Operator.kind op == 1  = ROP0
                     | otherwise = NOP0
                !val = TokenID.from (TokenID.ord xop + Operator.prec op)


packToken :: Token -> Bool
packToken t
    | t.tokid == VARID     = true
    | t.tokid == CONID     = true
    | t.tokid == QUALIFIER = true
    | t `is` '.' = true
    | otherwise = t.tokid >= PACKAGE && t.tokid <= INFIXR 

processInfix xs = fold single (Right specialT) xs where
    single (err@Left _) _ = err
    single (tree@Right _)  (t1:ts)
        | null ts = tree    -- Left (Pos t1 t1, msgdoc ("Malformed `" ++ t1.value ++ "´ declaration."))
        | Token.tokid t1 == INFIXL = mkInfix LOP0 ts tree
        | Token.tokid t1 == INFIXR = mkInfix ROP0 ts tree
        | Token.tokid t1 == INFIX  = mkInfix NOP0 ts tree
        | Token.tokid t1 == IMPORT = tree -- mkImport t1.line ts tree
        | otherwise = tree -- Left (Pos t1 t1, msgdoc ("Token `" ++ t1.value ++ "´ is invalid here"))
    single _ [] = error ("single: empty command")
    mkInfix op [] tree = error "Cannot happen, this is checked in single"
    mkInfix op (t1:ts) tree
        | Token INTCONST s _ _ _ <- t1, i <- s.atoi, i > 0 && i < 17,
          opid <- TokenID.from (TokenID.ord op + 17 - i) = fold (mkOp opid) tree ts
        | otherwise = Left (Pos t1 t1, msgdoc ("Illegal precedence `" ++ t1.value ++ "´, must be integer from range 1..16"))
    mkOp opid (err@Left _) token = err
    mkOp opid (Right tree) token
        | t `elem` [SOMEOP, VARID, CONID, CHAR], validop s = result
        | otherwise = Left (Pos token token, msgdoc ("Illegal operator: " ++ s))
        where
            t  = Token.tokid token
            !s = U.enclosed (Token.value token)
            result = Right (Tree.insert tree s opid)




data SM a b = SMT (Tree a (SM a b)) (Maybe b)
type SMCT = SM Char TokenID

statemachine :: SM Char TokenID -> [([Char], TokenID)] -> SM Char TokenID
statemachine sm [] = sm
statemachine (SMT tree Nothing) (([], t):bs) = statemachine (SMT tree (Just t)) bs
statemachine (SMT tree mb) ((c:cs, t):os)
    = statemachine (SMT (tree.insert c subsm) mb) other
    where
        startswith :: Char -> [Char] -> Bool
        startswith c (x:xs) = c == x
        startswith c [] = false
        (same, other) = partitioned (startswith c • fst) os
        subsm = statemachine (SMT Nil Nothing) ((cs, t):map (\(a,b) -> (tail a, b)) same)
statemachine (SMT tree (Just _)) (([], _):_) = error "This can only happen when keys are not unique."

interpret (SMT t r) [] = (r, [])
interpret (SMT t r) (ccs@c:cs) = case t.lookup c of
        Nothing -> (r, ccs)
        Just sm -> case interpret sm cs of
            (Nothing, _) -> (r, ccs)
            res          -> res

{--
 * build a statmachine for character sequences from a list of type [('String', 'TokenID')]
 -}
buildSMCT = statemachine (SMT Nil Nothing) • map (\(as,b) -> (unpacked as, b))

{--
 * Substitute char sequences with operators, 'SOMEOP' with operator,
 * QULIFIER OP with a single token by constructing a statemachine and
 * calling 'substOp' that does the real work.
 -}
substAllOp :: Tree String TokenID -> [Token] -> [Token]
-- construct the set of start characters of operators
substAllOp tree ts = substDot (substOp sm  tree ts) where
    sm = (buildSMCT • Tree.each) tree

{--
    Replace '.' with '•' where appropriate
    
    1. if @.@ appears after a @(@
    2. if @.@ appears before a @)@
    3. if @.@ is enclosed in whitespace
-}    
substDot (p:d:n:ts) 
    | is d '.', 
      is p '(' ||                       -- (.          looks like a section
      is n ')' ||                       -- .)          looks like a section
      not (p.vor d) && not (d.vor n)    -- foo . bar   probably function application 
        = p : substDot (d.{value="•", tokid=ROP1} :n:ts)
    | otherwise = p : substDot (d:n:ts)
substDot not3 = not3    -- less than 3 tokens

{--
 * Substitute char sequences with operators by recognizing the
 * longest sequence that forms an operator without backtracking,
 * 'SOMEOP' with operator.
 *
 *
 * The first argument is a statemachine of type 'SMCT' that reognizes all known operators.
 *
 * The statemachine was introduced when I tried out what would happen if I passed a file with
 * wrong encoding or a binary file. In that case, long sequences of bytes are recognized
 * by 'scan' as @Token { tokid = CHAR, ... }@ and then in the earlier version of 'substOp'
 * the longest sequence of 'CHAR' tokens was collected, a string was build,
 * checked against the operator table
 * and when there was no match, the last 'CHAR' was pushed back and the processing repeated
 * until we had a match or a string of length 0 and only then was the first character
 * taken as 'CHAR' and substOp continued with the rest of the sequence.
 *
 * While this is no problem with 2 or 3 character seqences, the runtime explodes with every
 * additional character. To avoid this, I invented the statemachine that sees immediately
 * when a string has no initial sequence that builds a known operator.
 -}
substOp :: SMCT -> Tree String TokenID -> [Token] -> [Token]
substOp start tree [] = []
substOp start tree (t:ts)
    | t.tokid == CHAR, forbidden (cval t)
                = t : substOp start tree ts
    | t.tokid == SOMEOP = case tree.lookupS (U.enclosed t.value) of
                Just tid -> Token tid  t.value t.line t.col t.offset : substOp start tree ts
                Nothing  -> Token NOP1 t.value t.line t.col t.offset : substOp start tree ts
    | t.tokid == CHAR
                = check (collect t ts) (t:ts)
    | otherwise = t : substOp start tree ts
    where
        -- qualified VARID = QVARID
        -- qualified CONID = QCONID
        -- qualified op    = op
        collect :: Token -> [Token] -> [Char]
        collect t [] = [cval t]
        collect t (x:ts)
            | x.tokid == CHAR, !(forbidden (cval x)), t.vor x = cval t:collect x ts
            | otherwise = [cval t]
        -- check [] ts = (head ts) : substOp start tree  (tail ts)
        check cs ts = case interpret start cs of
            (Nothing, _) -> head ts : substOp start tree (tail ts)
            (Just op, rest) ->
                (head ts::Token).{tokid = op, value = name rest}
                -- Token op (name rest) (Token.line (head ts)) (Token.col (head ts)) (Token.offset (head ts))
                : substOp start tree (drop (length cs - length rest) ts)
            -- otherwise = check tree (init xs) ts
          where name rest = packed (take (length cs - length rest) cs)

--- this is the lexical analysis pass
pass :: (String -> StG (Exception (Maybe OpArr))) -> StG [Token]
pass getop =
    do
        global <- getST
        let opts   = global.options

        fdata <- doio (slurp opts.source (maybe "utf-8" id opts.encoding))
        case fdata of
            Left exc -> do
                U.error Position.null (msgdoc ("Cannot read source file: " ++ show exc))
                stio []
            Right string -> passCS (CharSeq.fromString string) getop

{--
    This is the entry point for lexical analysis of a program contained in an immutable @java.lang.CharSequence@
-}
passCS :: CharSeq Immutable -> (String -> StG (Exception (Maybe OpArr))) -> StG [Token]
passCS cs getop =
    do
        g <- getST
        let prefix  =  g.options.prefix
        let tokens = layout [0] nocomms
            ifximps =  (reverse <~ findInfixImports) tokens
            tree0   = processInfix ifximps
        imps <- processImports prefix getop (Right specialT) ifximps
        let tree2 = either Left (ourinfix tree0) imps
            -- enter infix defined symbols last
            ourinfix (Right t0)    t = ourins t (each t0)
            ourinfix (left@Left _) _ = left
            ourins t [] = Right t
            ourins t ((k,v):kvs) = ourins (Tree.insert t k v) kvs
        either (failure) (success tokens) tree2
    where
        lexed = lex cs 1 1 0
        comments  =  filter Token.isComment lexed
        nocomms   =  filter Token.noComment lexed
        failure (n, s) = do
            U.error n s
            stio []
        success :: [Token] -> Tree String TokenID -> StG [Token]
        success tokens tree = do
            changeST Global.{sub <- SubSt.{optab = tree}}
            let !result = merge comments  (substAllOp tree tokens)
            changeST Global.{sub <- SubSt.{toks = Array.fromList result}}
            stio result
        merge :: [Token] -> [Token] -> [Token]
        merge a [] = a
        merge [] b = b
        merge (ass@a:as) (bss@b:bs)
            | a.offset < b.offset = a : merge as bss
            | otherwise           = b : merge ass bs

{--
    Get the names of the packages the source code in the argument depends on.

    This will be called from frege.imp.builders.FregeBuilder without 'Global'
-}
dependencies cs = (getPackages "" • findInfixImports) tokens
    where
        lexed = lex cs 1 1 0
        tokens   =  filter Token.noComment lexed

--- Wrapper around 'dependencies'
main ["-d" , file] = do
        fdata <- slurp file "utf-8"
        case fdata of
            Left exc -> throw exc
            Right cs -> do
                let deps = dependencies (CharSeq.fromString cs)
                mapM_ println deps
                return ()
--- test
main [fileortext] = do
        fdata <- slurp fileortext "utf-8"
        case fdata of
            Left exc -> do
                println (layout [0] $ lex (CharSeq.fromString fileortext) 1 1 0)
                return ()
            Right string -> do
                println (layout [0] $ lex (CharSeq.fromString string) 1 1 0)
                return ()
main xs = main [joined "\n" xs]